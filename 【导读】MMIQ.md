# MMIQ 
 ## 全文摘要 
###  
这篇论文提出了一个名为MM-IQ的评估框架，用于衡量多模态系统在抽象和推理方面的表现。该框架包含2710个精心挑选的测试项，涵盖了8种不同的推理模式。通过对领先开源和专有多模态模型进行系统的评估，研究人员发现这些模型的表现与随机猜测相差不大，这表明当前的多模态系统无法近似人类的基本推理能力。因此，需要实现具有颠覆性的进展以缩小认知差距。

![figure_4](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1337896763395059712/1337896763395059712_cut_Figure_4.png) 
## 论文速读 
### 论文方法 
### 方法描述

本文提出的MM-IQ是一种用于评估LMMs的AVR基准测试数据集。该数据集通过收集国家公务员考试等权威考试中的问题，并经过严格的筛选和分类，最终得到包含2710个问题、涵盖8种细粒度推理范式的全面的数据集。这些推理范式包括逻辑运算、数学、二维几何、三维几何、视觉指令、时间运动、空间关系和具体物体。其中，具体物体这一推理范式是基于现实世界中物体的分类，需要外部知识来解决问题。

### 方法改进

与现有的LMMs AVR数据集相比，MM-IQ采用了更严格的质量控制和数据采集方式。它不仅考虑了程序化合成数据的数量多样性，还注重了数据的多样性和质量。此外，该数据集还包括了翻译成英语的版本，以支持开放源代码社区的发展。

### 解决的问题

MM-IQ旨在为研究者提供一个更加全面、多样化和高质量的LMMs AVR基准测试数据集，以便更好地评估和比较不同模型的表现。同时，该数据集还可以帮助研究人员了解LMMs在不同推理任务上的表现，从而推动相关领域的研究和发展。
 
##  
### 论文实验 
本文主要介绍了针对多模态抽象推理任务的实验研究。首先，作者对四个开源和闭源的大规模语言模型进行了测试，并使用零样本提示的方式进行实验。其次，通过对这些模型在不同推理范式下的表现进行分析，得出了以下结论：

1. 人类的表现明显优于所有大规模语言模型，平均准确率为51.27%，而最佳的闭源模型Claude-3.5-Sonnet仅为27.49%。这表明了大规模语言模型在抽象推理任务中的局限性，强调了MM-IQ数据集的重要性。
2. 增加模型大小可以提高性能，从平均准确率20.81%增加到26.66%。此外，开源模型与私有模型之间的比较表明，72B的开源模型可以实现与私有模型相当的性能，说明了开源社区的潜力。
3. 对于不同的推理范式，人类和闭源模型在物体-具体推理方面表现更好，尤其是GPT-4o，其分数为50%。这可能是因为该范式需要额外的知识来解释图像中物体的具体性质。然而，在逻辑操作范式下，LMMs的平均分数仅为23.69%，因为解决逻辑操作需要识别更细粒度的关系并提取高阶抽象规则，这对LMMs提出了重大挑战。

接下来，作者通过人类评价错误响应的方式来进一步分析LMMs在MM-IQ上的失败原因。他们选择了三个代表性模型（Claude-3.5-Sonnet、Qwen2-VL-72B-Instruct和LLaVA-1.6-7B）作为研究对象，并对它们生成的错误响应进行了分类和分析。主要发现了以下几个问题：

1. 结构化输出：Claude-3.5-Sonnet等表现出较高准确性的模型倾向于生成更长且结构化的响应，因此增强生成结构化和详细的推理链的能力可能会提高准确性。
2. 抽象模式识别：错误响应的主要来源是依赖于简单规则导致的不正确推理。改进模型识别和应用高级抽象范式的能

![table_2](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1337896763395059712/1337896763395059712_cut_Table_2.png)

![table_3](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1337896763395059712/1337896763395059712_cut_Table_3.png)
 
##  
### 论文总结 
### 文章优点
本文提出了一种全新的评估大模型抽象推理能力的方法——MM-IQ，该方法覆盖了多样化的抽象视觉推理问题，并通过系统性的多样性设计避免了模式记忆的问题。同时，该方法采用了IQ测试的原则，将语言和任务知识与抽象推理能力分离，使得评估结果更加客观和准确。此外，文章还对该方法进行了详细的实验验证，并提出了改进方向，为后续的研究提供了有价值的参考。

### 方法创新点
MM-IQ是一种全面的抽象视觉推理基准，涵盖了多种不同的推理范式，并且通过系统性的多样性设计来防止模式记忆。该方法采用了IQ测试的原则，将语言和任务知识与抽象推理能力分离，从而能够更准确地评估大模型的抽象推理能力。此外，文章还提出了几个关键的改进方向，包括结构化推理、抽象图案识别、视觉理解和推理时间扩展等，这些方向有望进一步提高大模型的抽象推理能力。

### 未来展望
虽然MM-IQ提供了一个全面的抽象视觉推理基准，但是它仍然存在一些局限性，例如输入模态的限制和问题配置的不足。因此，在未来的研究中，可以考虑增加更多的输入模态和推理范式，以及扩大问题配置的范围，以更好地评估大模型的抽象推理能力。此外，还可以探索其他类型的抽象推理问题，如逻辑推理和自然语言推理等，以便更全面地评估大模型的认知能力。最后，可以结合深度强化学习等技术，进一步提高大模型的抽象推理能力和智能水平。
 
