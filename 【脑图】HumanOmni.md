# HumanOmni技术报告概述

## 1. 引言
- ### 视听理解重要性
  - 需要同时处理视觉和语音信息
  - 应用于教育、医疗等场景
- ### 当前方法局限性
  - 主要关注视觉语言模型，缺乏音频处理能力
  - 通用多模态模型缺少对人类中心场景的针对性设计

## 2. HumanOmni模型介绍
- ### 模型架构
  - 包含视觉、文本和音频处理分支
  - 特征融合模块根据指令动态调整权重
- ### 数据集建设
  - 构建包含2.4M视频片段的大规模数据集
  - 收集超过14M的指令数据，涵盖多样化任务
- ### 核心技术
  - 使用先进的视觉编码器和语言模型
  - 结合面部分支、身体分支和互动分支处理不同场景

## 3. 实验与评估
- ### 任务覆盖
  - 情感识别
  - 面部表情描述
  - 行为理解
  - 语音识别
- ### 性能比较
  - 优于现有视觉语言模型和多模态模型
  - 在特定任务上超出专属性模型性能

## 4. 结论
- ### HumanOmni优势
  - 多模态处理能力
  - 高效的数据利用和特征融合
- ### 展望
  - 开源以促进学术和工业界合作
  - 进一步提升在人类中心场景的理解能力
